import json
import sys
sys.path.append('../../')  # Add path to line SDK

from typing import AsyncGenerator

import openai
from loguru import logger

import config
from exa_utils import ExaSearchClient, convert_messages_to_openai, end_call_schema, web_search_schema

from line.events import AgentResponse, ToolResult
from line.nodes.conversation_context import ConversationContext
from line.nodes.reasoning import ReasoningNode
from line.tools.system_tools import EndCallArgs, EndCallTool, end_call


class ResearchNode(ReasoningNode):
    """
    Web research node that combines conversation with real-time web search.
    
    This node can engage in conversation and perform web searches when needed
    to provide accurate, up-to-date information to users.
    """
    
    def __init__(
        self,
        system_prompt: str,
        openai_client: openai.AsyncOpenAI,
        exa_client: ExaSearchClient,
    ):
        self.system_prompt = system_prompt
        super().__init__(system_prompt)
        
        self.openai_client = openai_client
        self.exa_client = exa_client
        self.tools = [web_search_schema, end_call_schema]
    
    async def process_context(self, context: ConversationContext) -> AsyncGenerator[AgentResponse, None]:
        """
        Process conversation context and generate responses with web search capability.
        
        Args:
            context: Conversation context with messages
            
        Yields:
            AgentResponse: Text responses to the user
            ToolResult: Results from tool calls
        """
        
        if not context.events:
            logger.info("No conversation messages to process")
            return
        
        try:
            # Convert messages to OpenAI format
            openai_messages = convert_messages_to_openai(context.events, self.system_prompt)
            
            # Call OpenAI with tools
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",  # Fast and cost-effective
                messages=openai_messages,
                max_tokens=config.MAX_OUTPUT_TOKENS,
                temperature=config.TEMPERATURE,
                tools=self.tools,
                tool_choice="auto"
            )
            
            message = response.choices[0].message
            
            # Handle tool calls
            if message.tool_calls:
                for tool_call in message.tool_calls:
                    function_name = tool_call.function.name
                    arguments = json.loads(tool_call.function.arguments)
                    
                    # Yield tool result for observability
                    yield ToolResult(
                        tool_name=function_name, 
                        tool_args=arguments,
                        tool_call_id=tool_call.id
                    )
                    
                    if function_name == "web_search":
                        # Perform web search
                        search_query = arguments.get("query", "")
                        
                        logger.info(f"üîç Performing web search: '{search_query}'")
                        
                        # Get search results
                        search_results = await self.exa_client.search_and_get_content(
                            query=search_query
                        )
                        
                        if "error" in search_results:
                            error_msg = search_results["error"]
                            logger.error(f"Search failed: {error_msg}")
                            
                            # Continue with error message
                            openai_messages.append({
                                "role": "system",
                                "content": f"Web search failed: {error_msg}. Please provide an answer based on your existing knowledge and let the user know about the search limitation."
                            })
                        else:
                            # Add search results to conversation
                            search_content = search_results["formatted_content"]
                            logger.info(f"üìä Search completed: {search_results['source_count']} sources found")
                            
                            openai_messages.append({
                                "role": "system", 
                                "content": f"Web search results:\n{search_content}\n\nPlease synthesize this information to answer the user's question. Cite sources when relevant."
                            })
                        
                        # Generate response with search results
                        final_response = await self.openai_client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=openai_messages,
                            max_tokens=config.MAX_OUTPUT_TOKENS,
                            temperature=config.TEMPERATURE
                        )
                        
                        final_content = final_response.choices[0].message.content
                        if final_content:
                            yield AgentResponse(content=final_content)
                    
                    elif function_name == EndCallTool.name():
                        # Handle end call
                        args = EndCallArgs(**arguments)
                        logger.info(f"ü§ñ End call requested: {args.goodbye_message}")
                        
                        async for item in end_call(args):
                            yield item
            
            else:
                # No tool calls, just return the response
                if message.content:
                    yield AgentResponse(content=message.content)
                else:
                    logger.warning("No content in response and no tool calls")
                    yield AgentResponse(content="I'm sorry, I didn't understand that. Could you please rephrase your question?")
        
        except Exception as e:
            logger.exception(f"Error in research node processing: {e}")
            yield AgentResponse(content="I apologize, but I encountered an error while processing your request. Please try again.")
